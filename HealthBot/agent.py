from datetime import datetime
from crewai import Agent
from toolkits.tools import SearchMilvusTool, AlertCaseManagerTool, RiskKeywordCheckTool, summarize_chunk_and_commit
from toolkits.redis_store import fetch_unsummarized_tail, fetch_all_history, get_summary, peek_next_n, peek_remaining, set_state_if, purge_user_session
from openai import OpenAI
import os, json

STM_MAX_CHARS = int(os.getenv("STM_MAX_CHARS", 1800))
SUMMARY_MAX_CHARS = int(os.getenv("SUMMARY_MAX_CHARS", 3000))
REFINE_CHUNK_ROUNDS = int(os.getenv("REFINE_CHUNK_ROUNDS", 20))
SUMMARY_CHUNK_SIZE = int(os.getenv("SUMMARY_CHUNK_SIZE", 5))

class UserProfileManager:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.profile_path = f"profiles/{user_id}.json"
        os.makedirs("profiles", exist_ok=True)
        if not os.path.exists(self.profile_path):
            with open(self.profile_path, "w", encoding="utf-8") as f:
                json.dump({"age": None, "personality": "æº«å’Œ", "refined_summary": ""}, f, ensure_ascii=False, indent=2)

    def load_profile(self) -> dict:
        with open(self.profile_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        if "refined_summary" not in data:
            data["refined_summary"] = ""; self.save_profile(data)
        return data

    def save_profile(self, profile: dict):
        with open(self.profile_path, "w", encoding="utf-8") as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)

    def update_refined_summary(self, text: str) -> None:
        prof = self.load_profile(); model = os.getenv("MODEL_NAME", "gpt-4o-mini")
        tag = f"--- {datetime.now().strftime('%Y-%m-%d')} ({model}) æ›´æ–° ---"
        prof["refined_summary"] = (prof.get("refined_summary","" ) + ("\n\n" if prof.get("refined_summary") else "") + tag + "\n" + text.strip() + "\n\n")
        self.save_profile(prof)

# ---- Prompt æ§‹å»º ----

def _shrink_tail(text: str, max_chars: int) -> str:
    if len(text) <= max_chars: return text
    tail = text[-max_chars:]; idx = tail.find("--- ")
    return tail[idx:] if idx != -1 else tail

def build_prompt_from_redis(user_id: str, k: int = 6) -> str:
    summary, _ = get_summary(user_id)
    summary = _shrink_tail(summary, SUMMARY_MAX_CHARS) if summary else ""
    rounds = fetch_unsummarized_tail(user_id, k=max(k,1))
    def render(rs): return "\n".join([f"é•·è¼©ï¼š{r['input']}\né‡‘å­«ï¼š{r['output']}" for r in rs])
    chat = render(rounds)
    while len(chat) > STM_MAX_CHARS and len(rounds) > 1:
        rounds = rounds[1:]; chat = render(rounds)
    if len(chat) > STM_MAX_CHARS and rounds: chat = chat[-STM_MAX_CHARS:]
    prof = UserProfileManager(user_id).load_profile()
    parts = [f"ä½¿ç”¨è€…å¹´é½¡ï¼š{prof.get('age','æœªçŸ¥')}ï¼Œå€‹æ€§ï¼š{prof.get('personality','æº«å’Œ')}"]
    if summary: parts.append("ðŸ“Œ æ­·å²æ‘˜è¦ï¼š\n" + summary)
    if prof.get('refined_summary'): parts.append("â­ é•·æœŸè¿½è¹¤é‡é»žï¼š\n" + prof['refined_summary'])
    if chat: parts.append("ðŸ•“ è¿‘æœŸå°è©±ï¼ˆæœªæ‘˜è¦ï¼‰ï¼š\n" + chat)
    return "\n\n".join(parts)

# ---- Agents ----

def create_guardrail_agent() -> Agent:
    return Agent(role="é¢¨éšªæª¢æŸ¥å“¡", goal="æ””æˆªå±éšª/é•æ³•/è‡ªå‚·å…§å®¹", backstory="ä½ æ˜¯ç³»çµ±ç¬¬ä¸€é“å®‰å…¨é˜²ç·šã€‚", tools=[RiskKeywordCheckTool()], memory=False, verbose=False)

def create_health_companion(user_id: str) -> Agent:
    return Agent(role="å¥åº·é™ªä¼´è€…", goal="ä»¥å°èªžé—œæ‡·é•·è€…å¥åº·èˆ‡å¿ƒç†ç‹€æ³ï¼Œå¿…è¦æ™‚é€šå ±", backstory="ä½ æ˜¯æœƒè¬›å°èªžçš„é‡‘å­«åž‹é™ªä¼´æ©Ÿå™¨äººï¼Œå›žè¦†æº«æš–å‹™å¯¦ã€‚", tools=[SearchMilvusTool(), AlertCaseManagerTool()], memory=False, verbose=False)

# ---- Refineï¼ˆmap-reduce over å…¨é‡ QAï¼‰ ----

def refine_summary(user_id: str) -> None:
    all_rounds = fetch_all_history(user_id)
    if not all_rounds: return
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # 1) åˆ†ç‰‡
    chunks = [all_rounds[i:i+REFINE_CHUNK_ROUNDS] for i in range(0, len(all_rounds), REFINE_CHUNK_ROUNDS)]
    partials = []
    for ch in chunks:
        conv = "\n".join([f"ç¬¬{i+1}è¼ª\né•·è¼©:{c['input']}\né‡‘å­«:{c['output']}" for i,c in enumerate(ch)])
        res = client.chat.completions.create(
            model=os.getenv("MODEL_NAME","gpt-4o-mini"), temperature=0.3,
            messages=[{"role":"system","content":"ä½ æ˜¯å°ˆæ¥­çš„å¥åº·å°è©±æ‘˜è¦åŠ©æ‰‹ã€‚"},{"role":"user","content":f"è«‹æ‘˜è¦æˆ 80-120 å­—ï¼ˆç—…æ³/æƒ…ç·’/ç”Ÿæ´»/å»ºè­°ï¼‰ï¼š\n\n{conv}"}],
        )
        partials.append((res.choices[0].message.content or "").strip())
    comb = "\n".join([f"â€¢ {s}" for s in partials])
    res2 = client.chat.completions.create(
        model=os.getenv("MODEL_NAME","gpt-4o-mini"), temperature=0.4,
        messages=[{"role":"system","content":"ä½ æ˜¯è‡¨åºŠå¿ƒç†èˆ‡å¥åº·ç®¡ç†é¡§å•ã€‚"},{"role":"user","content":f"æ•´åˆä»¥ä¸‹å¤šæ®µæ‘˜è¦ç‚ºä¸è¶…éŽ 180 å­—ã€æ¢åˆ—å¼ç²¾ç·»æ‘˜è¦ï¼ˆæ¯è¡Œä»¥ â€¢ é–‹é ­ï¼‰ï¼š\n\n{comb}"}],
    )
    final = (res2.choices[0].message.content or "").strip()
    UserProfileManager(user_id).update_refined_summary(final)

# ---- Finalizeï¼šè£œåˆ†æ®µæ‘˜è¦ â†’ Refine â†’ Purge ----

def finalize_session(user_id: str) -> None:
    set_state_if(user_id, expect="ACTIVE", to="FINALIZING")
    start, remaining = peek_remaining(user_id)
    if remaining:
        summarize_chunk_and_commit(user_id, start_round=start, history_chunk=remaining)
    refine_summary(user_id)
    purge_user_session(user_id)