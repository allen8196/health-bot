from crewai import Agent
from toolkits.tools import SearchMilvusTool, AlertCaseManagerTool, summarize_chunk_and_commit, ModelGuardrailTool
from toolkits.redis_store import fetch_unsummarized_tail, fetch_all_history, get_summary, peek_next_n, peek_remaining, set_state_if, purge_user_session
from openai import OpenAI
import os
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection
try:
    # utility æ–¼è¼ƒæ–°ç‰ˆæœ¬æä¾› has_collection ç­‰ API
    from pymilvus import utility  # type: ignore
except Exception:  # pragma: no cover
    utility = None  # å¾ŒçºŒä»¥èˆŠæ³•å›é€€
from embedding import safe_to_vector
import time

STM_MAX_CHARS = int(os.getenv("STM_MAX_CHARS", 1800))
SUMMARY_MAX_CHARS = int(os.getenv("SUMMARY_MAX_CHARS", 3000))
REFINE_CHUNK_ROUNDS = int(os.getenv("REFINE_CHUNK_ROUNDS", 20))
SUMMARY_CHUNK_SIZE = int(os.getenv("SUMMARY_CHUNK_SIZE", 5))

MEM_COLLECTION = os.getenv("MEM_COLLECTION", "user_memory")
def _get_embedding_dim():
    """å‹•æ…‹ç²å– embedding ç¶­åº¦ï¼Œé¿å…ç¡¬ç·¨ç¢¼é€ æˆä¸åŒ¹é…"""
    try:
        test_vec = safe_to_vector("test")
        return len(test_vec) if test_vec else 1536
    except Exception:
        return 1536

MEM_DIM = int(os.getenv("MEM_DIM", str(_get_embedding_dim())))
MEM_THRESHOLD = float(os.getenv("MEM_THRESHOLD", "0.80"))
MEM_TOPK = int(os.getenv("MEM_TOPK", "1"))

_mem_col = None

def _ensure_mem_col() -> Collection:
    global _mem_col
    if _mem_col:
        return _mem_col
    try:
        # å·²æœ‰é€£ç·šå‰‡æ²¿ç”¨ï¼›å¦å‰‡é€£ä¸€æ¬¡
        try:
            connections.get_connection("default")
        except Exception:
            connections.connect(alias="default", uri=os.getenv("MILVUS_URI", "http://localhost:19530"))
        # å»ºè¡¨ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰
        exists = False
        try:
            if utility is not None:
                exists = utility.has_collection(MEM_COLLECTION)
        except Exception:
            exists = False
        if not exists:
            try:
                # èˆŠç‰ˆ fallback
                exists = MEM_COLLECTION in [c.name for c in connections.get_connection("default").list_collections()]
            except Exception:
                exists = False
        if not exists:
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name="user_id", dtype=DataType.VARCHAR, max_length=64),
                FieldSchema(name="updated_at", dtype=DataType.INT64),
                FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=8192),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=MEM_DIM),
            ]
            schema = CollectionSchema(fields, description="per-user memory (text + embedding)")
            col = Collection(name=MEM_COLLECTION, schema=schema)
            # å‘é‡ç´¢å¼• + user_id ç´¢å¼•
            col.create_index("embedding", {"index_type":"HNSW","metric_type":"COSINE","params":{"M":16,"efConstruction":200}})
            try:
                col.create_index("user_id", {"index_type":"TRIE"})
            except Exception:
                # æŸäº›ç‰ˆæœ¬ä¸æ”¯æ´ TRIEï¼Œå¿½ç•¥å³å¯
                pass
        _mem_col = Collection(MEM_COLLECTION)
        _mem_col.load()
        return _mem_col
    except Exception as e:
        print(f"[mem ensure error] {e}")
        return None
def _prune_user_memory(user_id: str, keep: int = 30) -> int:
    """
    ä¿ç•™åŒä¸€ user_id æœ€æ–°çš„ keep ç­†ï¼ˆä¾ updated_atï¼‰ï¼Œå¤šçš„åˆªæ‰ã€‚
    å›å‚³åˆªé™¤çš„ç­†æ•¸ã€‚
    """
    col = _ensure_mem_col()
    if not col:
        return 0
    try:
        # æŠ“å‡ºé€™å€‹ user_id çš„ id èˆ‡ updated_at
        rows = col.query(
            expr=f'user_id == "{user_id}"',
            output_fields=["id", "updated_at"],
            limit=10000  # è¶³å¤ å¤§å³å¯ï¼›è³‡æ–™é‡æ›´å¤§æ™‚å†åšåˆ†é 
        )
    except Exception:
        return 0

    if not rows or len(rows) <= keep:
        return 0

    # ä¾ updated_at ç”±èˆŠåˆ°æ–°
    rows.sort(key=lambda r: r.get("updated_at", 0))
    n_over = len(rows) - keep
    to_delete_ids = [r["id"] for r in rows[:n_over] if "id" in r]

    if not to_delete_ids:
        return 0

    # ä¸»éµæ¬„ä½åå°±æ˜¯ schema çš„ nameï¼ˆä½ å®šç¾©çš„æ˜¯ "id"ï¼‰
    try:
        col.delete(expr=f"id in [{','.join(map(str, to_delete_ids))}]")
    except Exception as e:
        print(f"[prune memory delete error] {e}")
        return 0
    return len(to_delete_ids)

def _append_memory(user_id: str, text: str, vec: list) -> int:
    col = _ensure_mem_col()
    if not col or not vec or not text:
        return 0
    ms = int(time.time()*1000)
    # æŒ‰ schema é †åºæ’å…¥ï¼ˆè·³é auto_id ä¸»éµï¼‰
    col.insert([[user_id], [ms], [text], [vec]])
    _prune_user_memory(user_id)
    return 1

def _search_memory_top1(user_id: str, qv: list, threshold: float = MEM_THRESHOLD):
    col = _ensure_mem_col()
    if not col or not qv:
        return ""
    try:
        res = col.search(
            data=[qv], anns_field="embedding",
            param={"metric_type":"COSINE","params":{"ef":64}},
            limit=max(MEM_TOPK,1),
            expr=f'user_id == "{user_id}"',
            output_fields=["text"]
        )
        if res and len(res[0])>0:
            h = res[0][0]  # å–ç¬¬ä¸€ç­†
            if getattr(h, "score", 0.0) >= threshold:
                try:
                    text = h.entity.get("text") or ""
                    # éæ¿¾æ‰ç©ºå­—ä¸²çš„è¨˜éŒ„
                    return text if text.strip() else ""
                except Exception:
                    return ""
    except Exception as e:
        print(f"[mem search error] {e}")
    return ""

def _ensure_user_exists(user_id: str) -> None:
    """ç¢ºä¿è©² user_id åœ¨ Collection ä¸­å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å‰‡å»ºç«‹ç©ºè¨˜éŒ„"""
    col = _ensure_mem_col()
    if not col:
        return
    try:
        cnt = col.query(expr=f'user_id == "{user_id}"', output_fields=["id"], limit=1)
    except Exception:
        cnt = []
    if cnt:
        return
    
    # å»ºç«‹ç©ºè¨˜éŒ„ï¼šåªæœ‰ user_id å’Œ updated_atï¼Œtext å’Œ embedding ç‚ºç©ºå€¼
    try:
        ms = int(time.time() * 1000)
        # æ’å…¥ç©ºè¨˜éŒ„ï¼štext ç‚ºç©ºå­—ä¸²ï¼Œembedding ç‚ºé›¶å‘é‡
        zero_vec = [0.0] * MEM_DIM
        col.insert([[user_id], [ms], [""], [zero_vec]])
        print(f"[mem] ç‚º {user_id} å»ºç«‹ç©ºè¨˜éŒ„")
    except Exception as e:
        print(f"[mem] å»ºç«‹ç©ºè¨˜éŒ„å¤±æ•—: {e}")


# ---- Prompt æ§‹å»º ----

def _shrink_tail(text: str, max_chars: int) -> str:
    if len(text) <= max_chars: return text
    tail = text[-max_chars:]; idx = tail.find("--- ")
    return tail[idx:] if idx != -1 else tail

def build_prompt_from_redis(user_id: str, k: int = 6, current_input: str = "") -> str:
    summary, _ = get_summary(user_id)
    summary = _shrink_tail(summary, SUMMARY_MAX_CHARS) if summary else ""
    rounds = fetch_unsummarized_tail(user_id, k=max(k,1))
    def render(rs): return "\n".join([f"é•·è¼©ï¼š{r['input']}\né‡‘å­«ï¼š{r['output']}" for r in rs])
    chat = render(rounds)
    while len(chat) > STM_MAX_CHARS and len(rounds) > 1:
        rounds = rounds[1:]; chat = render(rounds)
    if len(chat) > STM_MAX_CHARS and rounds: chat = chat[-STM_MAX_CHARS:]
    parts = []
    if summary: parts.append("ğŸ“Œ æ­·å²æ‘˜è¦ï¼š\n" + summary)
    if chat: parts.append("ğŸ•“ è¿‘æœŸå°è©±ï¼ˆæœªæ‘˜è¦ï¼‰ï¼š\n" + chat)
    # --- ç¢ºä¿ä½¿ç”¨è€…å­˜åœ¨ï¼Œä¸¦é€²è¡Œè¨˜æ†¶æª¢ç´¢ ---
    _ensure_user_exists(user_id)
    if current_input:
        qv = safe_to_vector(current_input)
        if qv:  # åªæœ‰åœ¨å‘é‡åŒ–æˆåŠŸæ™‚æ‰æœç´¢
            mem_txt = _search_memory_top1(user_id, qv, threshold=MEM_THRESHOLD)
            if mem_txt and mem_txt.strip():  # åªæœ‰åœ¨æœ‰å¯¦éš›å…§å®¹æ™‚æ‰é¡¯ç¤º
                parts.insert(0, f"â­ è¿½è¹¤é‡é»ï¼š\n{mem_txt}")
    return "\n\n".join(parts)

# ---- Agents ----

def create_guardrail_agent() -> Agent:
    # é—œéµå­—å·¥å…·é€€å ´ â†’ å…¨é¢æ”¹ç‚º LLM åˆ¤æ–·
    return Agent(
        role="é¢¨éšªæª¢æŸ¥å“¡",
        goal="æ””æˆªé•æ³•/å±éšª/è‡ªå‚·/éœ€å°ˆæ¥­äººå£«ä¹‹å…·é«”æŒ‡å°å…§å®¹",
        backstory="ä½ æ˜¯ç³»çµ±ç¬¬ä¸€é“å®‰å…¨é˜²ç·šï¼Œåªè¼¸å‡ºåš´æ ¼åˆ¤æ–·çµæœã€‚",
        tools=[ModelGuardrailTool()],
        memory=False,
        verbose=False
    )

def create_health_companion(user_id: str) -> Agent:
    return Agent(role="å¥åº·é™ªä¼´è€…", goal="ä»¥å°èªé—œæ‡·é•·è€…å¥åº·èˆ‡å¿ƒç†ç‹€æ³ï¼Œå¿…è¦æ™‚é€šå ±", backstory="ä½ æ˜¯æœƒè¬›å°èªçš„é‡‘å­«å‹é™ªä¼´æ©Ÿå™¨äººï¼Œå›è¦†æº«æš–å‹™å¯¦ã€‚", tools=[SearchMilvusTool(), AlertCaseManagerTool()], memory=True, verbose=False)

# ---- Refineï¼ˆmap-reduce over å…¨é‡ QAï¼‰ ----

def refine_summary(user_id: str) -> None:
    all_rounds = fetch_all_history(user_id)
    if not all_rounds: return
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    # 1) åˆ†ç‰‡
    chunks = [all_rounds[i:i+REFINE_CHUNK_ROUNDS] for i in range(0, len(all_rounds), REFINE_CHUNK_ROUNDS)]
    partials = []
    for ch in chunks:
        conv = "\n".join([f"ç¬¬{i+1}è¼ª\né•·è¼©:{c['input']}\né‡‘å­«:{c['output']}" for i,c in enumerate(ch)])
        res = client.chat.completions.create(
            model=os.getenv("MODEL_NAME","gpt-4o-mini"), temperature=0.3,
            messages=[{"role":"system","content":"ä½ æ˜¯å°ˆæ¥­çš„å¥åº·å°è©±æ‘˜è¦åŠ©æ‰‹ã€‚"},{"role":"user","content":f"è«‹æ‘˜è¦æˆ 80-120 å­—ï¼ˆç—…æ³/æƒ…ç·’/ç”Ÿæ´»/å»ºè­°ï¼‰ï¼š\n\n{conv}"}],
        )
        partials.append((res.choices[0].message.content or "").strip())
    comb = "\n".join([f"â€¢ {s}" for s in partials])
    res2 = client.chat.completions.create(
        model=os.getenv("MODEL_NAME","gpt-4o-mini"), temperature=0.4,
        messages=[{"role":"system","content":"ä½ æ˜¯è‡¨åºŠå¿ƒç†èˆ‡å¥åº·ç®¡ç†é¡§å•ã€‚"},{"role":"user","content":f"æ•´åˆä»¥ä¸‹å¤šæ®µæ‘˜è¦ç‚ºä¸è¶…é 180 å­—ã€æ¢åˆ—å¼ç²¾ç·»æ‘˜è¦ï¼ˆæ¯è¡Œä»¥ â€¢ é–‹é ­ï¼‰ï¼š\n\n{comb}"}],
    )
    final = (res2.choices[0].message.content or "").strip()
    vec = safe_to_vector(final)
    if vec:
        _append_memory(user_id, final, vec)

# ---- Finalizeï¼šè£œåˆ†æ®µæ‘˜è¦ â†’ Refine â†’ Purge ----

def finalize_session(user_id: str) -> None:
    set_state_if(user_id, expect="ACTIVE", to="FINALIZING")
    start, remaining = peek_remaining(user_id)
    if remaining:
        summarize_chunk_and_commit(user_id, start_round=start, history_chunk=remaining)
    refine_summary(user_id)
    purge_user_session(user_id)
