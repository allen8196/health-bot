import os
import json
from time import time
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
from pymilvus import Collection, connections
from embedding import to_vector
from langchain_core.tools import tool  # âœ… ç”¨ä¾†è£é£¾å·¥å…·å‡½æ•¸
from langchain_openai import ChatOpenAI  # âœ… æ–°ç‰ˆæ¨¡å‹åŒ¯å…¥æ–¹å¼
from langchain.agents import initialize_agent, AgentType

from typing import Optional

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# åˆå§‹åŒ– LLM
llm_api = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
model_name = "gpt-4o-mini"
SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD"))
chat_model = ChatOpenAI(openai_api_key=os.getenv("OPENAI_API_KEY"), model_name=model_name)

# === ä½¿ç”¨è€…ç‹€æ…‹ç®¡ç† ===
def load_user_context(user_id: str) -> dict:
    """è¼‰å…¥å€‹äººåŒ–æ‘˜è¦èˆ‡è³‡æ–™ï¼Œè‹¥ä¸å­˜åœ¨å‰‡å»ºç«‹ç©ºæ¨¡æ¿"""
    os.makedirs("sessions", exist_ok=True)
    os.makedirs("profiles", exist_ok=True)

    summary_path = f"sessions/{user_id}_summary.json"
    profile_path = f"profiles/{user_id}.json"

    if not os.path.exists(summary_path):
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump({"summary": ""}, f)

    if not os.path.exists(profile_path):
        with open(profile_path, "w", encoding="utf-8") as f:
            json.dump({"age": None, "personality": "æº«å’Œ"}, f)

    with open(summary_path, "r", encoding="utf-8") as f:
        summary = json.load(f).get("summary", "")

    with open(profile_path, "r", encoding="utf-8") as f:
        profile = json.load(f)

    return {"summary": summary, "profile": profile}

# === Tool 1: RAG æŸ¥è©¢ ===
@tool
def search_milvus(query: str) -> str:
    """åœ¨ Milvus è³‡æ–™åº«ä¸­æŸ¥è©¢ COPD è¡›æ•™å•ç­”ï¼Œå›å‚³ç›¸ä¼¼å•é¡Œèˆ‡ç­”æ¡ˆ"""
    try:
        connections.connect(alias="default", uri="http://localhost:19530")
        collection = Collection("copd_qa")
        collection.load()
        user_vec = to_vector(query)
        if not isinstance(user_vec, list):
            user_vec = user_vec.tolist() if hasattr(user_vec, 'tolist') else list(user_vec)
        results = collection.search(
            data=[user_vec],
            anns_field="embedding",
            param={"metric_type": "COSINE", "params": {"nprobe": 10}},
            limit=5,
            output_fields=["question", "answer", "category"],
        )
        connections.disconnect(alias="default")

        chunks = []
        for hit in results[0]:
            if hit.score >= SIMILARITY_THRESHOLD:
                q = hit.entity.get("question")
                a = hit.entity.get("answer")
                cat = hit.entity.get("category")
                chunks.append(f"[{cat}] (ç›¸ä¼¼åº¦: {hit.score:.3f})\nQ: {q}\nA: {a}")

        return "\n\n".join(chunks) if chunks else "[æŸ¥ç„¡é«˜ç›¸ä¼¼åº¦çµæœ]"
    except Exception as e:
        return f"[Milvus éŒ¯èª¤] {e}"

# === Tool 2: å°è©±æ‘˜è¦ï¼Œä¸¦æ¸…ç©ºå°è©±è¨˜éŒ„ ===
@tool
def summarize_conversation(user_id: str) -> str:
    """æ‘˜è¦æœ€è¿‘å°è©±ï¼Œä¸¦æ›´æ–°ä½¿ç”¨è€…çš„æ‘˜è¦æª”æ¡ˆ"""
    session_path = f"sessions/{user_id}.json"
    summary_path = f"sessions/{user_id}_summary.json"
    if not os.path.exists(session_path):
        return "ç›®å‰ç„¡å¯ä¾›æ‘˜è¦çš„å°è©±ç´€éŒ„ã€‚"

    with open(session_path, "r", encoding="utf-8") as f:
        history = json.load(f)
    recent = history[-6:]
    text = "".join([f"ç¬¬{i+1}è¼ª:\né•·è¼©: {h['input']}\né‡‘å­«: {h['output']}\n\n" for i, h in enumerate(recent)])
    prompt = f"""
è«‹ç‚ºä»¥ä¸‹å°è©±ç”Ÿæˆæ‘˜è¦ï¼Œæ¶µè“‹å¥åº·å•é¡Œã€å»ºè­°é‡é»ã€æƒ…ç·’æ°›åœï¼š\n{text}è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œ100-150å­—ã€‚
"""

    try:
        res = llm_api.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯æ‘˜è¦åŠ©æ‰‹"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        summary = res.choices[0].message.content.strip()
        with open(summary_path, "w", encoding="utf-8") as f:
            json.dump({"summary": summary}, f, ensure_ascii=False, indent=2)
        with open(session_path, "w", encoding="utf-8") as f:
            json.dump([], f)  # æ¸…ç©ºåŸå§‹èŠå¤©ç´€éŒ„
        return summary
    except Exception as e:
        return f"[æ‘˜è¦éŒ¯èª¤] {e}"

# === CLI ä¸»ç¨‹å¼ ===
def main():
    user_id = input("è«‹è¼¸å…¥ç”¨æˆ¶ IDï¼š").strip()
    context = load_user_context(user_id)

    profile = context["profile"]
    summary = context["summary"]
    profile_txt = f"ä½¿ç”¨è€…å¹´é½¡ï¼š{profile.get('age', 'æœªçŸ¥')}ï¼Œå€‹æ€§ï¼š{profile.get('personality', 'æº«å’Œ')}\n"
    summary_txt = f"\n\nğŸ“Œ æ­·å²æ‘˜è¦ï¼š\n{summary}" if summary else ""

    system_msg = f"""
ä½ æ˜¯ä¸€ä½æœƒèªªå°ç£é–©å—èªçš„å¥åº·é™ªä¼´æ©Ÿå™¨äººã€‚
{profile_txt}
ä½ å¯ä»¥ä½¿ç”¨ search_milvus æŸ¥è©¢å¥åº·çŸ¥è­˜åº«ï¼Œæˆ–ä½¿ç”¨ summarize_conversation ä¾†ç¸½çµæœ€è¿‘çš„å°è©±ã€‚
è«‹æ ¹æ“šéœ€è¦æ±ºå®šæ˜¯å¦ä½¿ç”¨é€™äº›å·¥å…·ã€‚è«‹ä»¥è¦ªåˆ‡å°èªé€²è¡Œå°è©±ã€‚{summary_txt}
""".strip()

    tools = [search_milvus, summarize_conversation]  # âœ… ä½¿ç”¨ @tool è£é£¾å¾Œç›´æ¥åŠ å…¥

    agent = initialize_agent(
        tools=tools,
        llm=chat_model,
        agent=AgentType.OPENAI_FUNCTIONS,
        verbose=True,
        agent_kwargs={"system_message": system_msg}
    )

    while True:
        query = input("ğŸ§“ é•·è¼©ï¼š")
        if query.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ æ°æ°ï¼")
            break
        try:
            response = agent.run({"input": query, "user_id": user_id})
            print("ğŸ‘§ é‡‘å­«ï¼š", response)
        except Exception as e:
            print("âš ï¸ éŒ¯èª¤ï¼š", e)

if __name__ == "__main__":
    main()