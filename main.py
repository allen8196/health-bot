import os
import json
from time import time
from dotenv import load_dotenv
from langchain.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_ollama import OllamaLLM
from pymilvus import Collection, connections

from embedding import to_vector

# è¼‰å…¥ .env
load_dotenv()

# === å…¨åŸŸ LLM ===
PRIMARY_LLM = OllamaLLM(model="adsfaaron/taide-lx-7b-chat:q5")

# ç³»çµ±åƒæ•¸
SYSTEM_PROMPT = os.getenv("SYS_PROMPT").replace("\\n", "\n")
BASE_PROMPT_TEMPLATE = os.getenv("BASE_PROMPT_TEMPLATE")
SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD"))


def classify_intent(user_input: str, llm: OllamaLLM) -> str:
    try:
        # è®€å–å¤–éƒ¨ JSON æª”æ¡ˆ
        with open("intent.json", "r", encoding="utf-8") as f:
            categories = json.load(f)

        rag_keywords = "\n".join(f"- {k}" for k in categories.get("rag", []))
        chat_keywords = "\n".join(f"- {k}" for k in categories.get("chat", []))

        prompt = f"""
ä½ æ˜¯ä¸€å€‹åš´è¬¹çš„åˆ†é¡æ¨¡å‹ï¼Œåªèƒ½å°‡è¼¸å…¥åˆ†é¡ç‚ºå…©ç¨®ï¼šã€Œragã€æˆ–ã€Œchatã€ã€‚
è«‹æ ¹æ“šä»¥ä¸‹åˆ†é¡é‚è¼¯åˆ¤æ–·ä½¿ç”¨è€…çš„æ„åœ–ï¼Œåªè¼¸å‡º rag æˆ– chatï¼ˆåªèƒ½å°å¯«ï¼Œä¸èƒ½æœ‰æ¨™é»æˆ–å…¶ä»–æ–‡å­—ï¼‰ï¼š

ã€RAG åˆ†é¡æ¢ä»¶ã€‘
è‹¥å•é¡Œæ¶‰åŠä»¥ä¸‹é¡å‹çš„è³‡æ–™æŸ¥è©¢ï¼Œè«‹è¼¸å‡º ragï¼š
{rag_keywords}

ã€CHAT åˆ†é¡æ¢ä»¶ã€‘
è‹¥å•é¡Œåªæ˜¯ä¸€èˆ¬èŠå¤©ã€æ”¹å¯«ã€èªªæ˜æˆ–æƒ…æ„Ÿäº’å‹•ï¼Œä¸éœ€æŸ¥è©¢è³‡æ–™åº«ï¼Œè«‹è¼¸å‡º chatï¼š
{chat_keywords}

ã€ç¯„ä¾‹ã€‘
ä½¿ç”¨è€…è¼¸å…¥ï¼šè«‹å¹«æˆ‘æ‰¾å‡º COPD_QA.xlsx è£¡æåˆ°çš„é‹å‹•ç¨®é¡æœ‰å“ªäº› ğŸ‘‰ è¼¸å‡ºï¼šrag
ä½¿ç”¨è€…è¼¸å…¥ï¼šä»€éº¼æ˜¯ç¸®å”‡å‘¼å¸ï¼Ÿ ğŸ‘‰ è¼¸å‡ºï¼šrag
ä½¿ç”¨è€…è¼¸å…¥ï¼šè«‹å• COPD è·Ÿæ°£å–˜çš„å·®åˆ¥æ˜¯ä»€éº¼ ğŸ‘‰ è¼¸å‡ºï¼šrag
ä½¿ç”¨è€…è¼¸å…¥ï¼šå¹«æˆ‘ç”¨æ¯”è¼ƒå£èªçš„æ–¹å¼è§£é‡‹ä»€éº¼æ˜¯è‚ºæ°£è…« ğŸ‘‰ è¼¸å‡ºï¼šchat
ä½¿ç”¨è€…è¼¸å…¥ï¼šå¯ä»¥å¹«æˆ‘å¯«ä¸€å¥é¼“å‹µCOPDç—…äººçš„è©±å— ğŸ‘‰ è¼¸å‡ºï¼šchat
ä½¿ç”¨è€…è¼¸å…¥ï¼šå¹«æˆ‘æŠŠã€Œè…¹å¼å‘¼å¸æœ‰åŠ©æ¸›å°‘å‘¼å¸å›°é›£ã€æ”¹å¯«æˆé•·è¼©è½å¾—æ‡‚çš„èªªæ³• ğŸ‘‰ è¼¸å‡ºï¼šchat

ã€ç¾åœ¨è«‹åˆ†é¡ã€‘
ä½¿ç”¨è€…è¼¸å…¥ï¼š{user_input}
è«‹ä½ åªè¼¸å‡º rag æˆ– chatï¼š
        """.strip()

        print("prompt", prompt)
        result = llm.invoke([HumanMessage(content=prompt)]).strip().lower()

        return result if result in ["rag", "chat"] else "chat"  # fallback
    except Exception as e:
        print(f"[åˆ†é¡éŒ¯èª¤] {e}")
        return "chat"




def search_milvus(user_text: str) -> str:
    try:
        connections.connect(alias="default", uri="http://localhost:19530")
        collection = Collection("copd_qa")
        collection.load()
        user_vec = to_vector(user_text)
        results = collection.search(
            data=[user_vec],
            anns_field="embedding",
            param={"metric_type": "COSINE", "params": {"nprobe": 10}},
            limit=3,
            output_fields=["question", "answer", "category"],
        )
        connections.disconnect(alias="default")
        relevant_chunks = []
        for hit in results[0]:
            score = hit.score
            q = hit.entity.get("question")
            a = hit.entity.get("answer")
            cat = hit.entity.get("category")
            if score >= SIMILARITY_THRESHOLD:
                relevant_chunks.append(f"[{cat}]\nQ: {q}\nA: {a}")
        return "\n\n".join(relevant_chunks)
    except Exception as e:
        return f"[Milvus éŒ¯èª¤] {e}"


class HealthChatAgent:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.chat_history = []
        self.llm = PRIMARY_LLM

    def build_prompt(self, user_input: str, context: str = None):
        context_block = f"ğŸ“š ä»¥ä¸‹ç‚ºåƒè€ƒè³‡æ–™ï¼š\n{context.strip()}" if context else ""
        full_prompt = BASE_PROMPT_TEMPLATE.format(
            sys_prompt=SYSTEM_PROMPT,
            context_block=context_block,
            summary_block="",
            user_input=user_input.strip(),
        )

        messages = [SystemMessage(content=SYSTEM_PROMPT)]
        for pair in self.chat_history:
            messages.append(HumanMessage(content=pair["input"]))
            messages.append(HumanMessage(content=pair["output"]))
        messages.append(HumanMessage(content=full_prompt))

        return messages

    def chat(self, user_input: str):
        intent = classify_intent(user_input, self.llm)
        print("ğŸ” åˆ†é¡çµæœï¼š", intent)
        context = search_milvus(user_input) if intent == "rag" else None
        messages = self.build_prompt(user_input, context=context)
        response = self.llm.invoke(messages)
        self.chat_history.append({"input": user_input, "output": str(response)})
        return response


def main():
    print("ğŸ‘¤ å¤šä½¿ç”¨è€…å¥åº·å°è©±æ¸¬è©¦æ¨¡å¼")
    user_id = input("è«‹è¼¸å…¥æ¸¬è©¦ç”¨çš„ user_idï¼š").strip()
    agent = HealthChatAgent(user_id)
    print("\nâœ… å°è©±å•Ÿå‹•ï¼Œè¼¸å…¥ 'exit' çµæŸã€‚\n")
    while True:
        user_text = input("ğŸ§“ é•·è¼©ï¼š")
        if user_text.lower() in ["exit", "quit"]:
            break
        start_time = time()
        reply = agent.chat(user_text)
        print("ğŸ‘§ é‡‘å­«ï¼š", reply)
        print(f"â±ï¸ åŸ·è¡Œæ™‚é–“ï¼š{time() - start_time:.2f} ç§’\n")


if __name__ == "__main__":
    main()
