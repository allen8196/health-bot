import os
import json
from time import time
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI
from pymilvus import Collection, connections
from embedding import to_vector

# è¼‰å…¥ .env
load_dotenv()


class Bot:
    def __init__(self, user_id: str):
        """åˆå§‹åŒ– Bot å¯¦ä¾‹"""
        self.user_id = user_id
        self.chat_history = []
        self.conversation_count = 0  # å°è©±è¼ªæ•¸è¨ˆæ•¸å™¨
        
        # åˆå§‹åŒ– LLM
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model_name = "gpt-4o-mini"
        
        # Tool è¨­å®š
        self.tools = [
            {
                "type": "function",
                "function": {
                    "name": "search_milvus",
                    "description": "æŸ¥è©¢å¥åº·çŸ¥è­˜åº«ä»¥è¼”åŠ©å›ç­”ä½¿ç”¨è€…çš„å¥åº·å•é¡Œ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "ä½¿ç”¨è€…æå‡ºçš„å¥åº·å•é¡Œ",
                            }
                        },
                        "required": ["query"]
                    }
                }
            }
        ]
        
        # System Prompt
        self.system_prompt = """
ä½ æ˜¯ä¸€ä½æœƒèªªå°ç£é–©å—èªçš„å¥åº·é™ªä¼´æ©Ÿå™¨äººã€‚ä½ çš„å·¥ä½œæ˜¯é™ªä¼´é•·è€…èŠå¤©ï¼Œè‹¥å•é¡Œèˆ‡å¥åº·çŸ¥è­˜æœ‰é—œï¼Œä¸”ä½ ä¸ç¢ºå®šç­”æ¡ˆæ™‚ï¼Œå¯ä»¥ä½¿ç”¨è³‡æ–™åº«ï¼ˆsearch_milvusï¼‰æŸ¥è©¢å¾Œå†å›ç­”ã€‚

è«‹ä¿æŒæº«æš–ã€è¦ªåˆ‡ã€è¼•é¬†çš„èªæ°£ï¼Œå›è¦†æ™‚ç›¡é‡ä½¿ç”¨å°ç£é–©å—èªï¼Œå¿…è¦æ™‚ç©¿æ’ä¸­æ–‡å¹«åŠ©ç†è§£ã€‚

å¦‚æœä½ æœ‰ç”¨åˆ°è³‡æ–™åº«æŸ¥è©¢ï¼Œè«‹å°‡æŸ¥åˆ°çš„å…§å®¹èåˆæˆè‡ªå·±çš„èªæ°£å›ç­”ï¼Œä¸è¦åŸæ–‡è²¼ä¸Šã€‚
""".strip()

    def load_summaries(self) -> dict:
        """è¼‰å…¥ç¾æœ‰çš„æ‘˜è¦è¨˜éŒ„"""
        try:
            with open("summary.json", "r", encoding="utf-8") as f:
                content = f.read().strip()
                if not content:
                    return {}
                return json.loads(content)
        except (FileNotFoundError, json.JSONDecodeError):
            return {}

    def save_summaries(self, summaries: dict):
        """ä¿å­˜æ‘˜è¦è¨˜éŒ„åˆ° JSON æ–‡ä»¶"""
        try:
            with open("summary.json", "w", encoding="utf-8") as f:
                json.dump(summaries, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[æ‘˜è¦ä¿å­˜éŒ¯èª¤] {e}")

    def generate_summary(self) -> str:
        """ä½¿ç”¨ LLM ç”Ÿæˆå°è©±æ‘˜è¦"""
        if not self.chat_history:
            return "ç„¡å°è©±è¨˜éŒ„"
        
        # æº–å‚™å°è©±å…§å®¹
        conversation_text = ""
        for i, pair in enumerate(self.chat_history[-9:], 1):  # æœ€å¤šå–æœ€è¿‘9è¼ªå°è©±
            conversation_text += f"ç¬¬{i}è¼ª:\n"
            conversation_text += f"é•·è¼©: {pair['input']}\n"
            conversation_text += f"é‡‘å­«: {pair['output']}\n\n"
        
        # ç”Ÿæˆæ‘˜è¦çš„ prompt
        summary_prompt = f"""
è«‹ç‚ºä»¥ä¸‹çš„å°èªå¥åº·é™ªä¼´æ©Ÿå™¨äººå°è©±ç”Ÿæˆç°¡æ½”çš„æ‘˜è¦ã€‚
æ‘˜è¦æ‡‰è©²åŒ…æ‹¬ï¼š
1. ä¸»è¦è¨è«–çš„å¥åº·è©±é¡Œæˆ–é—œå¿ƒäº‹é …
2. é•·è¼©çš„ä¸»è¦éœ€æ±‚æˆ–å•é¡Œ
3. æ©Ÿå™¨äººæä¾›çš„å»ºè­°é‡é»
4. æ•´é«”å°è©±çš„æº«åº¦å’Œæ°›åœ

å°è©±å…§å®¹ï¼š
{conversation_text}

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œæ‘˜è¦æ§åˆ¶åœ¨100-150å­—å…§ã€‚
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å°è©±æ‘˜è¦åŠ©æ‰‹ï¼Œæ“…é•·æå–å°è©±é‡é»ã€‚"},
                    {"role": "user", "content": summary_prompt}
                ],
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}"

    def save_conversation_summary(self, trigger_reason="å®šæœŸæ‘˜è¦"):
        """ä¿å­˜å°è©±æ‘˜è¦"""
        if not self.chat_history:
            return
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self.generate_summary()
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # è¼‰å…¥ç¾æœ‰æ‘˜è¦
        summaries = self.load_summaries()
        
        # ç¢ºä¿ç”¨æˆ¶è¨˜éŒ„å­˜åœ¨
        if self.user_id not in summaries:
            summaries[self.user_id] = {
                "user_id": self.user_id,
                "summaries": []
            }
        
        # æ·»åŠ æ–°æ‘˜è¦
        new_summary = {
            "timestamp": timestamp,
            "conversation_count": len(self.chat_history),
            "trigger_reason": trigger_reason,
            "summary": summary
        }
        
        summaries[self.user_id]["summaries"].append(new_summary)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self.save_summaries(summaries)
        print(f"ğŸ“ å°è©±æ‘˜è¦å·²ä¿å­˜ ({trigger_reason}) - {len(self.chat_history)}è¼ªå°è©±")

    def search_milvus(self, query: str) -> str:
        """Milvus æŸ¥è©¢å‡½å¼ï¼Œåªè¿”å›ç›¸ä¼¼åº¦é«˜æ–¼é–¾å€¼çš„çµæœ"""
        try:
            # ç²å–ç›¸ä¼¼åº¦é–¾å€¼
            similarity_threshold = float(os.getenv("SIMILARITY_THRESHOLD"))
            
            connections.connect(alias="default", uri="http://localhost:19530")
            collection = Collection("copd_qa")
            collection.load()
            user_vec = to_vector(query)
            # ç¢ºä¿ user_vec æ˜¯æ­£ç¢ºçš„æ ¼å¼ï¼Œto_vector å·²è¿”å› list
            if not isinstance(user_vec, list):
                user_vec = user_vec.tolist() if hasattr(user_vec, 'tolist') else list(user_vec)
            
            results = collection.search(
                data=[user_vec],  # user_vec å·²ç¶“æ˜¯ listï¼ŒåŒ…åœ¨ [] ä¸­æˆç‚ºå‘é‡åˆ—è¡¨
                anns_field="embedding",
                param={"metric_type": "COSINE", "params": {"nprobe": 10}},
                limit=5,  # å¢åŠ æœç´¢æ•¸é‡ä»¥ä¾¿ç¯©é¸
                output_fields=["question", "answer", "category"],
            )
            connections.disconnect(alias="default")
            
            relevant_chunks = []
            for hit in results[0]:
                score = hit.score
                # åªæœ‰ç›¸ä¼¼åº¦é«˜æ–¼é–¾å€¼çš„çµæœæ‰åŠ å…¥
                if score >= similarity_threshold:
                    q = hit.entity.get("question")
                    a = hit.entity.get("answer")
                    cat = hit.entity.get("category")
                    relevant_chunks.append(f"[{cat}] (ç›¸ä¼¼åº¦: {score:.3f})\nQ: {q}\nA: {a}")
            
            if not relevant_chunks:
                return f"[æŸ¥è©¢çµæœ] æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦é«˜æ–¼ {similarity_threshold} çš„ç›¸é—œå…§å®¹"
            
            return "\n\n".join(relevant_chunks)
        except Exception as e:
            return f"[Milvus éŒ¯èª¤] {e}"

    def chat(self, user_input: str) -> str:
        """èŠå¤©ä¸»é‚è¼¯"""
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # åŠ å…¥æ­·å²å°è©±
        for pair in self.chat_history:
            messages.append({"role": "user", "content": pair["input"]})
            messages.append({"role": "assistant", "content": pair["output"]})
        
        messages.append({"role": "user", "content": user_input})

        # Step 1: è®“æ¨¡å‹æ±ºå®šæ˜¯å¦è¦ä½¿ç”¨ Tool
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            tools=self.tools,
            tool_choice="auto"
        )

        msg = response.choices[0].message

        # Step 2: è‹¥æ¨¡å‹æƒ³ä½¿ç”¨ Tool
        if msg.tool_calls:
            tool_call = msg.tool_calls[0]
            fn_args = json.loads(tool_call.function.arguments)
            result = self.search_milvus(fn_args["query"])

            # Step 3: å›å‚³ Tool çµæœçµ¦æ¨¡å‹ï¼Œè«‹å®ƒæ•´åˆå›ç­”
            # æ·»åŠ  assistant çš„ tool call æ¶ˆæ¯
            messages.append({
                "role": "assistant",
                "content": "",  # æ”¹ç‚ºç©ºå­—ä¸²è€Œé None
                "tool_calls": msg.tool_calls  # ä½¿ç”¨æ­£ç¢ºçš„ tool_calls æ ¼å¼
            })
            # æ·»åŠ  tool çš„å›æ‡‰æ¶ˆæ¯
            messages.append({
                "role": "tool",
                "tool_call_id": tool_call.id,
                "content": result
            })

            final_response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages
            )
            reply = final_response.choices[0].message.content
        else:
            reply = msg.content

        # ä¿å­˜å°è©±æ­·å²
        self.chat_history.append({"input": user_input, "output": reply})
        self.conversation_count += 1
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼æ‘˜è¦ï¼ˆæ¯3è¼ªå°è©±ï¼‰
        if self.conversation_count % 3 == 0:
            self.save_conversation_summary(f"å®šæœŸæ‘˜è¦-ç¬¬{self.conversation_count}è¼ª")
        
        return reply

    def get_chat_history(self):
        """ç²å–èŠå¤©æ­·å²"""
        return self.chat_history

    def clear_chat_history(self):
        """æ¸…é™¤èŠå¤©æ­·å²"""
        self.chat_history = []

    def get_user_id(self):
        """ç²å–ç”¨æˆ¶ ID"""
        return self.user_id

    def get_user_summaries(self):
        """ç²å–ç•¶å‰ç”¨æˆ¶çš„æ‰€æœ‰æ‘˜è¦è¨˜éŒ„"""
        summaries = self.load_summaries()
        return summaries.get(self.user_id, {"user_id": self.user_id, "summaries": []})

    def print_summary_history(self):
        """é¡¯ç¤ºç”¨æˆ¶çš„æ‘˜è¦æ­·å²"""
        user_data = self.get_user_summaries()
        summaries = user_data.get("summaries", [])
        
        if not summaries:
            print(f"ğŸ“ ç”¨æˆ¶ {self.user_id} æš«ç„¡æ‘˜è¦è¨˜éŒ„")
            return
        
        print(f"\nğŸ“š ç”¨æˆ¶ {self.user_id} çš„å°è©±æ‘˜è¦æ­·å²ï¼š")
        print("=" * 50)
        
        for i, summary in enumerate(summaries, 1):
            print(f"æ‘˜è¦ #{i}")
            print(f"æ™‚é–“ï¼š{summary.get('timestamp', 'N/A')}")
            print(f"å°è©±è¼ªæ•¸ï¼š{summary.get('conversation_count', 'N/A')}")
            print(f"è§¸ç™¼åŸå› ï¼š{summary.get('trigger_reason', 'N/A')}")
            print(f"æ‘˜è¦å…§å®¹ï¼š{summary.get('summary', 'N/A')}")
            print("-" * 30)


# === CLI äº’å‹•æ¸¬è©¦ ===
def main():
    print("ğŸ‘¤ å°èªè¡›æ•™èŠå¤©å•Ÿå‹•")
    user_id = input("è«‹è¼¸å…¥æ¸¬è©¦ç”¨ IDï¼š").strip()
    
    # å‰µå»º Bot å¯¦ä¾‹
    bot = Bot(user_id)
    
    print(f"\nâœ… ç”¨æˆ¶ {user_id} çš„å°è©±é–‹å§‹ï¼Œè¼¸å…¥ exit é›¢é–‹\n")
    print("ğŸ’¡ ç‰¹æ®ŠæŒ‡ä»¤ï¼š")
    print("   ğŸ“ 'summary' - æŸ¥çœ‹æ‘˜è¦æ­·å²")
    print("   ğŸ”„ 'save_summary' - æ‰‹å‹•ä¿å­˜ç•¶å‰æ‘˜è¦")
    print("   ğŸ‘‹ 'exit' - é€€å‡ºä¸¦ä¿å­˜æœ€çµ‚æ‘˜è¦\n")
    
    try:
        while True:
            user_input = input("ğŸ§“ é•·è¼©ï¼š")
            
            # è™•ç†ç‰¹æ®ŠæŒ‡ä»¤
            if user_input.lower() in ["exit", "quit"]:
                # åœ¨é€€å‡ºå‰ä¿å­˜æœ€çµ‚æ‘˜è¦
                if bot.chat_history:
                    print("\nğŸ“ æ­£åœ¨ç”Ÿæˆæœ€çµ‚å°è©±æ‘˜è¦...")
                    bot.save_conversation_summary("å°è©±çµæŸæ‘˜è¦")
                    print("âœ… æ‘˜è¦å·²ä¿å­˜åˆ° summary.json")
                print("ğŸ‘‹ å†è¦‹ï¼")
                break
            elif user_input.lower() == "summary":
                bot.print_summary_history()
                continue
            elif user_input.lower() == "save_summary":
                if bot.chat_history:
                    bot.save_conversation_summary("æ‰‹å‹•è§¸ç™¼æ‘˜è¦")
                    print("âœ… æ‘˜è¦å·²æ‰‹å‹•ä¿å­˜")
                else:
                    print("âš ï¸ å°šç„¡å°è©±è¨˜éŒ„å¯æ‘˜è¦")
                continue
            
            start = time()
            reply = bot.chat(user_input)
            print("ğŸ‘§ é‡‘å­«ï¼š", reply)
            print(f"â±ï¸ è€—æ™‚ï¼š{time() - start:.2f} ç§’\n")
    except KeyboardInterrupt:
        # è™•ç† Ctrl+C ä¸­æ–·
        if bot.chat_history:
            print("\n\nğŸ“ æ­£åœ¨ç”Ÿæˆæœ€çµ‚å°è©±æ‘˜è¦...")
            bot.save_conversation_summary("æ„å¤–ä¸­æ–·æ‘˜è¦")
            print("âœ… æ‘˜è¦å·²ä¿å­˜åˆ° summary.json")
        print("\nğŸ‘‹ å°è©±å·²ä¸­æ–·ï¼Œå†è¦‹ï¼")

if __name__ == "__main__":
    main()
