# embed_bge_chunk.py

from sentence_transformers import SentenceTransformer
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np

# ---------- Step 1ï¼šè¼‰å…¥ä¸­æ–‡ Embedding æ¨¡å‹ ----------
print("ğŸ”„ è¼‰å…¥ embedding æ¨¡å‹ BAAI/bge-small-zh ä¸­...")
model = SentenceTransformer("BAAI/bge-small-zh")
instruction = "ç‚ºé€™å€‹å¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨æ–¼æª¢ç´¢ç›¸é—œæ–‡ä»¶ï¼š"

# ---------- Step 2ï¼šè®€å–è¡›æ•™æ–‡ç«  ----------
with open("qa.txt", "r", encoding="utf-8") as f:
    content = f.read()

# ---------- Step 3ï¼šèªæ„å°å‘åˆ‡æ®µ ----------
splitter = RecursiveCharacterTextSplitter(
    separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""],
    chunk_size=300,
    chunk_overlap=50
)
chunks = splitter.split_text(content)

# ---------- Step 4ï¼šå°‡æ¯å€‹ chunk åš embedding ----------
print(f"ğŸ“„ ç¸½å…±æœ‰ {len(chunks)} å€‹æ®µè½ï¼Œé–‹å§‹é€²è¡Œå‘é‡è½‰æ›...")
chunk_vectors = model.encode([instruction + chunk for chunk in chunks])

print(f"\nâœ… å®Œæˆï¼æ¯æ®µå‘é‡ç¶­åº¦ï¼š{chunk_vectors.shape[1]}")
print("ğŸ“Œ ç¬¬ä¸€æ®µåŸæ–‡ï¼š", chunks[0])
print("ğŸ“Œ ç¬¬ä¸€æ®µå‘é‡ï¼ˆå‰ 5 ç¶­ï¼‰ï¼š", chunk_vectors[0][:5])

# ---------- Step 5ï¼šä½¿ç”¨è€…è¼¸å…¥ä¸¦è½‰æ›ç‚ºå‘é‡ ----------
user_input = input("\nè«‹è¼¸å…¥ä½ æƒ³è©¢å•çš„å…§å®¹ï¼š")
user_vector = model.encode([instruction + user_input])[0]
print("ğŸ§  ä½¿ç”¨è€…è¼¸å…¥å‘é‡ï¼ˆå‰ 5 ç¶­ï¼‰ï¼š", user_vector[:5])
